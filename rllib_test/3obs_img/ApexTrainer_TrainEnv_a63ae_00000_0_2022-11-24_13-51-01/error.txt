Failure # 1 (occurred at 2022-11-24_13-51-29)
Traceback (most recent call last):
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\tune\ray_trial_executor.py", line 901, in get_next_executor_event
    future_result = ray.get(ready_future)
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\_private\client_mode_hook.py", line 105, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\worker.py", line 1811, in get
    raise value
ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::ApexTrainer.__init__()[39m (pid=3140, ip=127.0.0.1, repr=ApexTrainer)
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\util\tracing\tracing_helper.py", line 462, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\rllib\agents\trainer.py", line 1035, in _init
    raise NotImplementedError
NotImplementedError

During handling of the above exception, another exception occurred:

[36mray::ApexTrainer.__init__()[39m (pid=3140, ip=127.0.0.1, repr=ApexTrainer)
  File "python\ray\_raylet.pyx", line 656, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 697, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 663, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 667, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 614, in ray._raylet.execute_task.function_executor
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\_private\function_manager.py", line 701, in actor_method_executor
    return method(__ray_actor, *args, **kwargs)
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\util\tracing\tracing_helper.py", line 462, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\rllib\agents\trainer.py", line 831, in __init__
    config, logger_creator, remote_checkpoint_dir, sync_function_tpl
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\tune\trainable.py", line 149, in __init__
    self.setup(copy.deepcopy(self.config))
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\util\tracing\tracing_helper.py", line 462, in _resume_span
    return method(self, *_args, **_kwargs)
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\rllib\agents\trainer.py", line 933, in setup
    self.workers, self.config, **self._kwargs_for_execution_plan()
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\rllib\agents\dqn\apex.py", line 174, in execution_plan
    node=platform.node(),  # localhost
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\rllib\utils\actors.py", line 121, in create_colocated_actors
    node=node,
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\rllib\utils\actors.py", line 185, in try_create_colocated
    co_located, non_co_located = split_colocated(actors, node=node)
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\rllib\utils\actors.py", line 220, in split_colocated
    hosts = ray.get([a.get_host.remote() for a in actors])
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\_private\client_mode_hook.py", line 105, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\worker.py", line 1811, in get
    raise value
ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::MultiAgentReplayBuffer.__init__()[39m (pid=26484, ip=127.0.0.1, repr=<ray.rllib.execution.buffers.multi_agent_replay_buffer.MultiAgentReplayBuffer object at 0x0000014375173048>)
  File "python\ray\_raylet.pyx", line 621, in ray._raylet.execute_task
  File "C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\lib\site-packages\ray\_private\memory_monitor.py", line 164, in raise_if_low_memory
    used_gb, total_gb, self.error_threshold
ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node PC-Plissonneau is used (15.08 / 15.79 GB). The top 10 memory consumers are:

PID	MEM	COMMAND
3140	3.3GiB	C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\python.exe C:\Users\Aplissonn
23884	0.45GiB	C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\python.exe C:\Users\Aplissonn
12628	0.4GiB	python training_ray.py
26484	0.35GiB	C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\python.exe C:\Users\Aplissonn
24052	0.35GiB	C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\python.exe C:\Users\Aplissonn
14236	0.33GiB	C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\python.exe C:\Users\Aplissonn
27324	0.32GiB	C:\Users\Aplissonneau\AppData\Local\Continuum\anaconda3\envs\multitask\python.exe C:\Users\Aplissonn
9052	0.31GiB	C:\Program Files\Microsoft Office\root\Office16\OUTLOOK.EXE
14548	0.29GiB	C:\Users\Aplissonneau\AppData\Local\Microsoft\Teams\current\Teams.exe --type=renderer --enable-wer -
19008	0.27GiB	C:\Program Files\Microsoft Office\Root\Office16\POWERPNT.EXE C:\Users\Aplissonneau\Downloads\Present

In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.
---
--- Tip: Use the `ray memory` command to list active objects in the cluster.
--- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.
---

